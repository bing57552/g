import requests
import time
from concurrent.futures import ThreadPoolExecutor

# 1. è®¾ç½®å…¨çƒå¤šåœ°åŸŸæºï¼šå½“éƒ¨åˆ†æºå¤±æ•ˆæ—¶ï¼Œè„šæœ¬ä¼šè‡ªåŠ¨ä»å…¶ä»–å¤‡ä»½æºæŠ“å–åœ°å€
SOURCES = {
    "north_america": "https://raw.githubusercontent.com/YueChan/Live/main/m3u/america.m3u",
    "europe": "https://raw.githubusercontent.com/YueChan/Live/main/m3u/europe.m3u",
    "asia_chinese": "https://raw.githubusercontent.com/YueChan/Live/main/m3u/asia.m3u",
    "southeast_asia": "https://raw.githubusercontent.com/YueChan/Live/main/m3u/singapore_malaysia.m3u",
    "global_zh": "https://iptv-org.github.io/iptv/languages/zho.m3u",
    "movie_itv": "https://itvlist.cc/itv.m3u"
}

# 2. ç”µå½±ã€ç”µè§†å‰§ç²¾å‡†ç­›é€‰å…³é”®è¯
KEYWORDS = ["ç”µå½±", "ç”µè§†å‰§", "å‰§åœº", "å½±é™¢", "TVB", "ç¿¡ç¿ å°", "æ˜Ÿæ²³", "åè¯­", "Channel 8", "Ué¢‘é“", "Drama", "Movie"]

def check_url(item):
    """è‡ªåŠ¨å‰”é™¤å¡é¡¿å’ŒéŸ³ç”»ä¸åŒæ­¥çš„ç›´æ’­æº"""
    name_info, url = item
    # æ¨¡æ‹ŸçœŸå®æµè§ˆå™¨è¯·æ±‚ï¼Œé˜²æ­¢è¢«æœåŠ¡å™¨å±è”½å¯¼è‡´çš„æ–­æµæˆ–åŒæ­¥é—®é¢˜
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }
    try:
        start_time = time.time()
        # å°†è¶…æ—¶è®¾ç½®ä¸º 2.0sã€‚è™½ç„¶å»¶è¿Ÿå¢åŠ ï¼Œä½†èƒ½æœ‰æ•ˆä¿ç•™æµ·å¤–é«˜è´¨é‡æº
        response = requests.head(url, headers=headers, timeout=2.0, allow_redirects=True)
        end_time = time.time()
        
        # åªæœ‰è¿”å› 200 (æœ‰æ•ˆ) çš„æºæ‰ä¼šè¢«åŠ å…¥åˆ—è¡¨
        if response.status_code == 200:
            return {"name": name_info, "url": url, "speed": end_time - start_time}
    except:
        pass
    return None

def main():
    unique_channels = {}
    
    for filename, url in SOURCES.items():
        try:
            print(f"ğŸ”„ æ­£åœ¨è·å–æœ€æ–°æœ‰æ•ˆæº: {filename}")
            r = requests.get(url, timeout=15)
            r.raise_for_status()
            lines = r.text.split('\n')
            temp_list = []
            
            for i in range(len(lines)):
                if "#EXTINF" in lines[i] and i + 1 < len(lines):
                    name_info = lines[i].strip()
                    link = lines[i+1].strip()
                    
                    if link.startswith('http'):
                        clean_name = name_info.split(',')[-1].strip()
                        # ä»…å¤„ç†åŒ…å«å½±è§†å…³é”®è¯çš„é¢‘é“
                        if any(kw.lower() in clean_name.lower() for kw in KEYWORDS):
                            temp_list.append((name_info, link))

            # 3. å¹¶å‘æ£€æµ‹ä¸æµ‹é€Ÿ
            with ThreadPoolExecutor(max_workers=30) as executor:
                results = list(executor.map(check_url, temp_list))

            # 4. è‡ªåŠ¨æ›¿æ¢é€»è¾‘ï¼šåŒåé¢‘é“åªä¿ç•™å“åº”é€Ÿåº¦æœ€å¿«çš„åœ°å€
            for res in results:
                if res:
                    c_name = res["name"].split(',')[-1].strip()
                    if c_name not in unique_channels or res["speed"] < unique_channels[c_name]["speed"]:
                        unique_channels[c_name] = res
            
        except Exception as e:
            print(f"âš ï¸ æº {filename} æš‚æ—¶ä¸å¯ç”¨: {e}")

    # 5. ç”Ÿæˆæœ€æ–°çš„ all.m3u æ–‡ä»¶
    final_content = ["#EXTM3U"]
    for res in unique_channels.values():
        final_content.append(f"{res['name']}\n{res['url']}")

    with open("all.m3u", "w", encoding="utf-8") as f:
        f.write("\n".join(final_content))
    
    print(f"\nğŸš€ è‡ªåŠ¨æ›´æ–°å®Œæˆï¼å·²åŒæ­¥å…¨çƒå½±è§†èµ„æºã€‚å½“å‰æœ‰æ•ˆé¢‘é“æ€»æ•°: {len(unique_channels)}")

if __name__ == "__main__":
    main()



